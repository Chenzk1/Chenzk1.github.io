<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.2.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/mylogo-32x32-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/mylogo-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/mylogo-16x16-next.png">
  <link rel="mask-icon" href="/images/mylogo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.0/css/all.min.css">

<script class="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"chenzk1.github.io","root":"/","scheme":"Gemini","version":"8.0.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":false,"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"motion":{"enable":false,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}};
  </script>

  <meta name="description" content="[TOC] 线性回归1. 简单介绍一下线性回归。 线性：两个变量之间的关系是一次函数关系的——图象是直线，叫做线性。 非线性：两个变量之间的关系不是一次函数关系的——图象不是直线，叫做非线性。 回归：人们在测量事物的时候因为客观条件所限，求得的都是测量值，而不是事物真实的值，为了能够得到真实值，无限次的进行测量，最后通过这些测量数据计算回归到真实值，这就是回归的由来。 线性回归就是利用的样本$D&#x3D;">
<meta property="og:type" content="article">
<meta property="og:title" content="线性回归&amp;逻辑回归">
<meta property="og:url" content="https://chenzk1.github.io/2021/12/10/%E3%80%90%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%9D%A2%E8%AF%95%E9%A2%98%E3%80%91%E2%80%94%E2%80%94%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92+%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/index.html">
<meta property="og:site_name" content="Kayden&#39;s Blog">
<meta property="og:description" content="[TOC] 线性回归1. 简单介绍一下线性回归。 线性：两个变量之间的关系是一次函数关系的——图象是直线，叫做线性。 非线性：两个变量之间的关系不是一次函数关系的——图象不是直线，叫做非线性。 回归：人们在测量事物的时候因为客观条件所限，求得的都是测量值，而不是事物真实的值，为了能够得到真实值，无限次的进行测量，最后通过这些测量数据计算回归到真实值，这就是回归的由来。 线性回归就是利用的样本$D&#x3D;">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200101212656597.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0hlaXRhbzUyMDA=,size_16,color_FFFFFF,t_70">
<meta property="article:published_time" content="2021-12-09T16:00:00.000Z">
<meta property="article:modified_time" content="2021-12-11T09:40:52.203Z">
<meta property="article:author" content="Kayden">
<meta property="article:tag" content="ML">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://img-blog.csdnimg.cn/20200101212656597.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0hlaXRhbzUyMDA=,size_16,color_FFFFFF,t_70">


<link rel="canonical" href="https://chenzk1.github.io/2021/12/10/%E3%80%90%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%9D%A2%E8%AF%95%E9%A2%98%E3%80%91%E2%80%94%E2%80%94%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92+%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/">


<script class="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>线性回归&逻辑回归 | Kayden's Blog</title>
  






  <noscript>
  <style>
  body { margin-top: 2rem; }

  .use-motion .menu-item,
  .use-motion .sidebar,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header {
    visibility: visible;
  }

  .use-motion .header,
  .use-motion .site-brand-container .toggle,
  .use-motion .footer { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle,
  .use-motion .custom-logo-image {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line {
    transform: scaleX(1);
  }

  .search-pop-overlay, .sidebar-nav { display: none; }
  .sidebar-panel { display: block; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">Kayden's Blog</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">Mamba forever.</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <section class="post-toc-wrap sidebar-panel">
          <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92"><span class="nav-number">1.</span> <span class="nav-text">线性回归</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-%E7%AE%80%E5%8D%95%E4%BB%8B%E7%BB%8D%E4%B8%80%E4%B8%8B%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E3%80%82"><span class="nav-number">1.1.</span> <span class="nav-text">1. 简单介绍一下线性回归。</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%9A%84%E5%81%87%E8%AE%BE%E5%87%BD%E6%95%B0%E6%98%AF%E4%BB%80%E4%B9%88%E5%BD%A2%E5%BC%8F%EF%BC%9F"><span class="nav-number">1.2.</span> <span class="nav-text">2. 线性回归的假设函数是什么形式？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%9A%84%E4%BB%A3%E4%BB%B7-%E6%8D%9F%E5%A4%B1-%E5%87%BD%E6%95%B0%E6%98%AF%E4%BB%80%E4%B9%88%E5%BD%A2%E5%BC%8F%EF%BC%9F"><span class="nav-number">1.3.</span> <span class="nav-text">3. 线性回归的代价(损失)函数是什么形式？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-%E7%AE%80%E8%BF%B0%E5%B2%AD%E5%9B%9E%E5%BD%92%E4%B8%8ELasso%E5%9B%9E%E5%BD%92%E4%BB%A5%E5%8F%8A%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF%E3%80%82"><span class="nav-number">1.4.</span> <span class="nav-text">4. 简述岭回归与Lasso回归以及使用场景。</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E8%A6%81%E6%B1%82%E5%9B%A0%E5%8F%98%E9%87%8F%E6%9C%8D%E4%BB%8E%E6%AD%A3%E6%80%81%E5%88%86%E5%B8%83%E5%90%97%EF%BC%9F"><span class="nav-number">1.5.</span> <span class="nav-text">5. 线性回归要求因变量服从正态分布吗？</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92"><span class="nav-number">2.</span> <span class="nav-text">逻辑回归</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-%E7%AE%80%E5%8D%95%E4%BB%8B%E7%BB%8D%E4%B8%80%E4%B8%8B%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92"><span class="nav-number">2.1.</span> <span class="nav-text">1. 简单介绍一下逻辑回归</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-%E7%AE%80%E5%8D%95%E4%BB%8B%E7%BB%8D%E4%B8%80%E4%B8%8BSigmoid%E5%87%BD%E6%95%B0"><span class="nav-number">2.2.</span> <span class="nav-text">2. 简单介绍一下Sigmoid函数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E7%9A%84%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E6%98%AF%E4%BB%80%E4%B9%88"><span class="nav-number">2.3.</span> <span class="nav-text">3. 逻辑回归的损失函数是什么</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-%E5%8F%AF%E4%BB%A5%E8%BF%9B%E8%A1%8C%E5%A4%9A%E5%88%86%E7%B1%BB%E5%90%97%EF%BC%9F"><span class="nav-number">2.4.</span> <span class="nav-text">4.可以进行多分类吗？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E7%9A%84%E4%BC%98%E7%BC%BA%E7%82%B9"><span class="nav-number">2.5.</span> <span class="nav-text">5.逻辑回归的优缺点</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-%E9%80%BB%E8%BE%91%E6%96%AF%E7%89%B9%E5%9B%9E%E5%BD%92%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%AF%B9%E7%89%B9%E5%BE%81%E8%BF%9B%E8%A1%8C%E7%A6%BB%E6%95%A3%E5%8C%96%E3%80%82"><span class="nav-number">2.6.</span> <span class="nav-text">6. 逻辑斯特回归为什么要对特征进行离散化。</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#7-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E4%B8%8E%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E7%9A%84%E5%8C%BA%E5%88%AB"><span class="nav-number">2.7.</span> <span class="nav-text">7.  线性回归与逻辑回归的区别</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#8-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E6%9C%89%E5%93%AA%E4%BA%9B%E5%BA%94%E7%94%A8"><span class="nav-number">2.8.</span> <span class="nav-text">8. 逻辑回归有哪些应用</span></a></li></ol></li></ol></div>
      </section>
      <!--/noindex-->

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Kayden</p>
  <div class="site-description" itemprop="description">Kayden's Blog</div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">39</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">20</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <a href="https://github.com/Chenzk1" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;Chenzk1" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:chenzk666@gmail.com" title="E-Mail → mailto:chenzk666@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>


  <div class="links-of-blogroll site-overview-item animated">
    <div class="links-of-blogroll-title"><i class="fa fa-globe fa-fw"></i>
      Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://andrewsher.github.io/" title="https:&#x2F;&#x2F;andrewsher.github.io&#x2F;" rel="noopener" target="_blank">Andrewsher's blog</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="http://shorey.tech/" title="http:&#x2F;&#x2F;shorey.tech&#x2F;" rel="noopener" target="_blank">Shorey's blog</a>
        </li>
    </ul>
  </div>

      </section>
        <div class="back-to-top animated">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">
      

      

  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="https://chenzk1.github.io/2021/12/10/%E3%80%90%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%9D%A2%E8%AF%95%E9%A2%98%E3%80%91%E2%80%94%E2%80%94%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92+%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Kayden">
      <meta itemprop="description" content="Kayden's Blog">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Kayden's Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          线性回归&逻辑回归
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2021-12-10 00:00:00" itemprop="dateCreated datePublished" datetime="2021-12-10T00:00:00+08:00">2021-12-10</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Edited on</span>
        <time title="Modified: 2021-12-11 17:40:52" itemprop="dateModified" datetime="2021-12-11T17:40:52+08:00">2021-12-11</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Learning/" itemprop="url" rel="index"><span itemprop="name">Learning</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <p>[TOC]</p>
<h1 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h1><h2 id="1-简单介绍一下线性回归。"><a href="#1-简单介绍一下线性回归。" class="headerlink" title="1. 简单介绍一下线性回归。"></a>1. 简单介绍一下线性回归。</h2><ul>
<li>线性：两个变量之间的关系<strong>是</strong>一次函数关系的——图象<strong>是直线</strong>，叫做线性。</li>
<li>非线性：两个变量之间的关系<strong>不是</strong>一次函数关系的——图象<strong>不是直线</strong>，叫做非线性。</li>
<li>回归：人们在测量事物的时候因为客观条件所限，求得的都是测量值，而不是事物真实的值，为了能够得到真实值，无限次的进行测量，最后通过这些测量数据计算<strong>回归到真实值</strong>，这就是回归的由来。</li>
<li>线性回归就是利用的样本$D=(\mathrm{x}_i, \mathrm{y}_i)<br>$，$ \mathrm{i}=1,2,3 \ldots \mathrm{N}, \mathrm{x}_i$是特征数据，可能是一个，也可能是多个，通过有监督的学习，学习到由$x$到$y$的映射$h$，利用该映射关系对未知的数据进行预估，因为$y$为连续值，所以是回归问题。</li>
</ul>
<a id="more"></a>
<h2 id="2-线性回归的假设函数是什么形式？"><a href="#2-线性回归的假设函数是什么形式？" class="headerlink" title="2. 线性回归的假设函数是什么形式？"></a>2. 线性回归的假设函数是什么形式？</h2><p>线性回归的假设函数（$\theta<em>{0}$表示截距项，$ x</em>{0} = 1$，方便矩阵表达）：</p>
<script type="math/tex; mode=display">
f(x)=\theta_{0} x_{0}+\theta_{1} x_{1}+\theta_{2} x_{2} \ldots+\theta_{n} x_{n}  = \theta ^TX</script><p>其中$\theta,x$都是列向量</p>
<h2 id="3-线性回归的代价-损失-函数是什么形式？"><a href="#3-线性回归的代价-损失-函数是什么形式？" class="headerlink" title="3. 线性回归的代价(损失)函数是什么形式？"></a>3. 线性回归的代价(损失)函数是什么形式？</h2><script type="math/tex; mode=display">
MSE: \qquad J\left(\theta_{0}, \theta_{1}\right)=\frac{1}{2 m} \sum_{i=1}^{m}\left(y_{i}-h_{\theta}\left(x_{i}\right)\right)^{2}</script><h2 id="4-简述岭回归与Lasso回归以及使用场景。"><a href="#4-简述岭回归与Lasso回归以及使用场景。" class="headerlink" title="4. 简述岭回归与Lasso回归以及使用场景。"></a>4. 简述岭回归与Lasso回归以及使用场景。</h2><ul>
<li><p>目的：</p>
<ul>
<li><p>解决线性回归出现的过拟合的请况。</p>
</li>
<li><p>解决在通过正规方程方法求解$\theta$的过程中出现的$X^TX$不可逆的请况。</p>
</li>
</ul>
</li>
<li><p>本质：</p>
<ul>
<li>约束(限制)要优化的参数 </li>
</ul>
</li>
</ul>
<p>这两种回归均通过在损失函数中引入<strong>正则化项</strong>来达到目的：</p>
<p><strong>线性回归的损失函数：</strong></p>
<script type="math/tex; mode=display">
J(\theta)=\frac{1}{2 m} \sum_{i=1}^{m}\left(h_{\theta}\left(x^{(i)}\right)-y^{(i)}\right)^{2}</script><ul>
<li><strong>岭回归</strong><ul>
<li>损失函数：</li>
</ul>
</li>
</ul>
<script type="math/tex; mode=display">
J(\theta)=\frac{1}{2 m} \sum_{i=1}^{m}\left(h_{\theta}\left(x^{(i)}\right)-y^{(i)}\right)^{2}+\lambda \sum_{j=1}^{n} \theta_{j}^{2}</script><ul>
<li><strong>Lasso回归</strong><ul>
<li>损失函数</li>
</ul>
</li>
</ul>
<script type="math/tex; mode=display">
J(\theta)=\frac{1}{2 m} \sum_{i=1}^{m}\left(h_{\theta}\left(x^{(i)}\right)-y^{(i)}\right)^{2}+\lambda \sum_{j=1}^{n} |\theta_{j}|</script><p>本来Lasso回归与岭回归的解空间是全部区域，但通过正则化添加了一些约束，使得解空间变小了，甚至在个别正则化方式下，解变得稀疏了。<br><img src="https://img-blog.csdnimg.cn/20200101212656597.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0hlaXRhbzUyMDA=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" style="zoom:50%;" /><br>如图所示，这里的$w_1$，$w_2$都是模型的参数，要优化的目标参数，那个红色边框包含的区域，其实就是解空间，正如上面所说，这个时候，解空间“缩小了”，你只能在这个缩小了的空间中，寻找使得目标函数最小的$w_1$，$w_2$。左边图的解空间是圆的，是由于采用了$L2$范数正则化项的缘故，右边的是个四边形，是由于采用了$L1$范数作为正则化项的缘故，大家可以在纸上画画，$L2$构成的区域一定是个圆，$L1$构成的区域一定是个四边形。</p>
<p>再看看那蓝色的圆圈，再次提醒大家，这个<strong>坐标轴和特征（数据）没关系</strong>，它完全是参数的坐标系，每一个圆圈上，可以取无数个$w_1$，$w_2$，这些$w_1$，$w_2$有个共同的特点，用它们计算的目标函数值是相等的！那个蓝色的圆心，就是实际最优参数，但是由于我们对解空间做了限制，所以最优解只能在“缩小的”解空间中产生。</p>
<p>蓝色的圈圈一圈又一圈，代表着参数$w_1$，$w_2$在不停的变化，并且是在解空间中进行变化（这点注意，图上面没有画出来，估计画出来就不好看了），直到脱离了解空间，也就得到了图上面的那个$w^*$，这便是目标函数的最优参数。</p>
<p>对比一下左右两幅图的$w^*$，我们明显可以发现，右图的$w^*$的$w_1$分量是0，有没有感受到一丝丝凉意？稀疏解诞生了！是的，这就是我们想要的稀疏解，我们想要的简单模型。$L1$比$L2$正则化更容易产生稀疏矩阵。</p>
<ul>
<li><p>补充</p>
<ul>
<li><p><strong>ElasticNet 回归</strong>： 线性回归 + L1正则化 + L2 正则化。</p>
<ul>
<li><p>ElasticNet在我们发现用Lasso回归太过(太多特征被稀疏为0),而岭回归也正则化的不够(回归系数衰减太慢)的时候，可以考虑使用ElasticNet回归来综合，得到比较好的结果。</p>
</li>
<li><p>损失函数</p>
<script type="math/tex; mode=display">
J(\theta)=\frac{1}{2} \sum_{i}^{m}\left(y^{(i)}-\theta^{T} x^{(i)}\right)^{2}+\lambda\left(\rho \sum_{j}^{n}\left|\theta_{j}\right|+(1-\rho) \sum_{j}^{n} \theta_{j}^{2}\right)</script></li>
</ul>
</li>
<li><p><strong>LWR(局部加权)回归</strong>：</p>
<ul>
<li><p>局部加权线性回归是在线性回归的基础上对每一个测试样本（训练的时候就是每一个训练样本）在其已有的样本进行一个加权拟合，<strong>权重的确定</strong>可以通过一个核来计算，常用的有<strong>高斯核</strong>（离测试样本越近，权重越大，反之越小），这样对每一个测试样本就得到了不一样的权重向量，所以最后得出的拟合曲线不再是线性的了，这样就增加的模型的复杂度来更好的拟合非线性数据。</p>
</li>
<li><p>损失函数</p>
<script type="math/tex; mode=display">
J(\theta)=\frac{1}{2} \sum_{i=1}^{m} w^{(i)}\left(h_{\theta}\left(x^{(i)}\right)-y^{(i)}\right)^{2}</script></li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="5-线性回归要求因变量服从正态分布吗？"><a href="#5-线性回归要求因变量服从正态分布吗？" class="headerlink" title="5. 线性回归要求因变量服从正态分布吗？"></a>5. 线性回归要求因变量服从正态分布吗？</h2><p><strong>线性回归的假设前提是噪声服从正态分布，即因变量服从正态分布。但实际上难以达到，因变量服从正态分布时模型拟合效果更好。</strong></p>
<p>参考资料： <a target="_blank" rel="noopener" href="http://www.julyedu.com/question/big/kp_id/23/ques_id/2914">http://www.julyedu.com/question/big/kp_id/23/ques_id/2914</a> </p>
<h1 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h1><h2 id="1-简单介绍一下逻辑回归"><a href="#1-简单介绍一下逻辑回归" class="headerlink" title="1. 简单介绍一下逻辑回归"></a>1. 简单介绍一下逻辑回归</h2><p>逻辑回归用来解决<strong>分类</strong>问题，线性回归的结果$Y$带入一个非线性变换的<strong>Sigmoid函数</strong>中，得到$[0,1]$之间取值范围的数$S$，$S$可以把它看成是一个概率值，如果我们设置概率阈值为0.5，那么$S$大于0.5可以看成是正样本，小于0.5看成是负样本，就可以进行分类了。</p>
<ul>
<li>逻辑回归的本质： 极大似然估计</li>
<li>逻辑回归的激活函数：Sigmoid</li>
<li>逻辑回归的代价函数：交叉熵</li>
</ul>
<h2 id="2-简单介绍一下Sigmoid函数"><a href="#2-简单介绍一下Sigmoid函数" class="headerlink" title="2. 简单介绍一下Sigmoid函数"></a>2. 简单介绍一下Sigmoid函数</h2><p>函数公式如下：</p>
<script type="math/tex; mode=display">
S(t)=\frac{1}{1+e^{-t}}</script><p>函数中$t$无论取什么值，其结果都在$[0,{1}]$的区间内，回想一下，一个分类问题就有两种答案，一种是“是”，一种是“否”，那0对应着“否”，1对应着“是”，那又有人问了，你这不是$[0,1]$的区间吗，怎么会只有0和1呢？这个问题问得好，我们假设分类的<strong>阈值</strong>是0.5，那么超过0.5的归为1分类，低于0.5的归为0分类，阈值是可以自己设定的。</p>
<p>好了，接下来我们把$\theta^T X+b$带入$t$中就得到了我们的逻辑回归的一般模型方程：</p>
<p>逻辑回归的<strong>假设函数</strong>：</p>
<script type="math/tex; mode=display">
H(\theta, b)=\frac{1}{1+e^{(\theta^T X+b)}}</script><p>结果$P$也可以理解为概率，换句话说概率大于0.5的属于1分类，概率小于0.5的属于0分类，这就达到了分类的目的。</p>
<h2 id="3-逻辑回归的损失函数是什么"><a href="#3-逻辑回归的损失函数是什么" class="headerlink" title="3. 逻辑回归的损失函数是什么"></a>3. 逻辑回归的损失函数是什么</h2><p>逻辑回归的损失函数是<strong>对数似然函数</strong>，函数公式如下：</p>
<script type="math/tex; mode=display">
\operatorname{cost}\left(h_{\theta}(x), y\right)=\left\{\begin{aligned}-\log \left(h_{\theta}(x)\right) & \qquad  y=1 \\-\log \left(1-h_{\theta}(x)\right) & \qquad  y=0 \end{aligned}\right.</script><p><strong>两式合并</strong>得到<strong>概率分布表达式</strong>：</p>
<script type="math/tex; mode=display">
(P(y|x,\theta ) = h_{\theta}(x)^y(1-h_{\theta}(x))^{1-y})</script><p> <strong>对数似然函数最大化</strong>得到<strong>似然函数的代数表达式</strong>为 ：</p>
<script type="math/tex; mode=display">
L(\theta) = \prod\limits_{i=1}^{m}(h_{\theta}(x^{(i)}))^{y^{(i)}}(1-h_{\theta}(x^{(i)}))^{1-y^{(i)}}</script><p> <strong>对似然函数对数化取反</strong>得到<strong>损失函数表达式</strong> ：</p>
<script type="math/tex; mode=display">
J(\theta) = -lnL(\theta) = -\sum\limits_{i=1}^{m}(y^{(i)}log(h_{\theta}(x^{(i)}))+ (1-y^{(i)})log(1-h_{\theta}(x^{(i)})))</script><ul>
<li>为何不能用mse</li>
</ul>
<p><a target="_blank" rel="noopener" href="http://sofasofa.io/forum_main_post.php?postid=1001792">解释</a></p>
<h2 id="4-可以进行多分类吗？"><a href="#4-可以进行多分类吗？" class="headerlink" title="4.可以进行多分类吗？"></a>4.可以进行多分类吗？</h2><p>多分类问题一般将二分类推广到多分类的方式有三种，一对一，一对多，多对多。</p>
<ul>
<li><p>一对一：</p>
<ul>
<li>将$N$个类别两两配对，产生$N(N-1)/2$个二分类任务，测试阶段新样本同时交给所有的分类器，最终结果通过投票产生。</li>
</ul>
</li>
<li><p>一对多：</p>
<ul>
<li>每一次将一个例作为正例，其他的作为反例，训练$N$个分类器，测试时如果只有一个分类器预测为正类，则对应类别为最终结果，如果有多个，则一般选择置信度最大的。从分类器角度一对一更多，但是每一次都只用了2个类别，因此当类别数很多的时候一对一开销通常更小(只要训练复杂度高于$O(N)$即可得到此结果)。</li>
</ul>
</li>
<li><p>多对多：</p>
<ul>
<li>若干各类作为正类，若干个类作为反类。注意正反类必须特殊的设计。</li>
</ul>
</li>
</ul>
<h2 id="5-逻辑回归的优缺点"><a href="#5-逻辑回归的优缺点" class="headerlink" title="5.逻辑回归的优缺点"></a>5.逻辑回归的优缺点</h2><ul>
<li><p>优点</p>
<ul>
<li>LR能以概率的形式输出结果，而非只是0,1判定。</li>
<li>LR的可解释性强、可控度高、训练速度快</li>
</ul>
</li>
<li><p>缺点</p>
<ul>
<li><p>对模型中自变量多重共线性较为敏感</p>
<p>例如两个高度相关自变量同时放入模型，可能导致较弱的一个自变量回归符号不符合预期，符号被扭转。需要利用因子分析或者变量聚类分析等手段来选择代表性的自变量，以减少候选变量之间的相关性；</p>
</li>
<li><p>预测结果呈$S$型，因此从$log(odds)$向概率转化的过程是非线性的，在两端随着$log(odds)$值的变化，概率变化很小，边际值太小，slope太小，而中间概率的变化很大，很敏感。 导致很多区间的变量变化对目标概率的影响没有区分度，无法确定阀值。</p>
</li>
</ul>
</li>
</ul>
<h2 id="6-逻辑斯特回归为什么要对特征进行离散化。"><a href="#6-逻辑斯特回归为什么要对特征进行离散化。" class="headerlink" title="6. 逻辑斯特回归为什么要对特征进行离散化。"></a>6. 逻辑斯特回归为什么要对特征进行离散化。</h2><ul>
<li><p>逻辑回归属于广义线性模型，表达能力受限；单变量离散化为N个后，每个变量有单独的权重，相当于为模型引入了非线性，能够提升模型表达能力，加大拟合；离散特征的增加和减少都很容易，易于模型的快速迭代； </p>
</li>
<li><p>稀疏向量内积乘法运算速度快，计算结果方便存储，容易扩展； </p>
</li>
<li><p>简化模型：特征离散化以后，起到了简化了逻辑回归模型的作用，降低了模型过拟合的风险。</p>
</li>
<li><p>方便交叉与特征组合：离散化后可以进行特征交叉，由$M+N$个变量变为$M*N$个变量，进一步引入非线性，提升表达能力； </p>
</li>
</ul>
<h2 id="7-线性回归与逻辑回归的区别"><a href="#7-线性回归与逻辑回归的区别" class="headerlink" title="7.  线性回归与逻辑回归的区别"></a>7.  线性回归与逻辑回归的区别</h2><ul>
<li><p>线性回归的样本的输出，都是连续值，$ y\in (-\infty ,+\infty )$，而逻辑回归中$y\in (0,1)$，只能取0和1。</p>
</li>
<li><p>对于拟合函数也有本质上的差别： </p>
<ul>
<li>线性回归：$f(x)=\theta ^{T}x=\theta <em>{1}x </em>{1}+\theta <em>{2}x </em>{2}+…+\theta <em>{n}x </em>{n}$</li>
<li>逻辑回归：$f(x)=P(y=1|x;\theta )=g(\theta ^{T}x)$，其中，$g(z)=\frac{1}{1+e^{-z}}$</li>
</ul>
</li>
</ul>
<p>  线性回归的拟合函数，是对$f(x)$的输出变量$y$的拟合，而逻辑回归的拟合函数是对为1类样本的概率的拟合。</p>
<ul>
<li><p>为什么要以1类样本的概率进行拟合呢，为什么可以这样拟合呢？ </p>
<p>$\theta ^{T}x=0$就相当于是1类和0类的决策边界： </p>
<p>当$\theta ^{T}x&gt;0$，则$y&gt;0.5$；若$\theta ^{T}x\rightarrow +\infty $，则$y \rightarrow  1 $，即$y$为1类; </p>
<p>当$\theta ^{T}x&lt;0$，则$y&lt;0.5$；若$\theta ^{T}x\rightarrow -\infty $，则$y \rightarrow  0 $，即$y$为0类; </p>
</li>
</ul>
<ul>
<li><p>这个时候就能看出区别，在线性回归中$\theta ^{T}x$为预测值的拟合函数；而在逻辑回归中$\theta ^{T}x$为决策边界。下表为线性回归和逻辑回归的区别。</p>
<p><center>线性回归和逻辑回归的区别</p>
</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:center">线性回归</th>
<th style="text-align:center">逻辑回归</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">目的</td>
<td style="text-align:center">预测</td>
<td style="text-align:center">分类</td>
</tr>
<tr>
<td style="text-align:center">$y^{(i)}$</td>
<td style="text-align:center">未知</td>
<td style="text-align:center">（0,1）</td>
</tr>
<tr>
<td style="text-align:center">函数</td>
<td style="text-align:center">拟合函数</td>
<td style="text-align:center">预测函数</td>
</tr>
<tr>
<td style="text-align:center">参数计算方式</td>
<td style="text-align:center">最小二乘法</td>
<td style="text-align:center">极大似然估计</td>
</tr>
</tbody>
</table>
</div>
<p> 下面具体解释一下： </p>
<ol>
<li>拟合函数和预测函数什么关系呢？简单来说就是将拟合函数做了一个逻辑函数的转换，转换后使得$y^{(i)} \in (0,1)$;</li>
<li>最小二乘和最大似然估计可以相互替代吗？回答当然是不行了。我们来看看两者依仗的原理：最大似然估计是计算使得数据出现的可能性最大的参数，依仗的自然是Probability。而最小二乘是计算误差损失。</li>
</ol>
<h2 id="8-逻辑回归有哪些应用"><a href="#8-逻辑回归有哪些应用" class="headerlink" title="8. 逻辑回归有哪些应用"></a>8. 逻辑回归有哪些应用</h2><ul>
<li>CTR预估/推荐系统的learning to rank/各种分类场景。</li>
<li>某搜索引擎厂的广告CTR预估基线版是LR。</li>
<li>某电商搜索排序/广告CTR预估基线版是LR。</li>
<li>某电商的购物搭配推荐用了大量LR。</li>
<li>某现在一天广告赚1000w+的新闻app排序基线是LR。</li>
</ul>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/ML/" rel="tag"># ML</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2021/12/10/%E3%80%90%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%9D%A2%E8%AF%95%E9%A2%98%E3%80%91%E2%80%94%E2%80%94%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D/" rel="prev" title="机器学习面试题-梯度下降">
                  <i class="fa fa-chevron-left"></i> 机器学习面试题-梯度下降
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2021/12/10/%E3%80%90%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%9D%A2%E8%AF%95%E9%A2%98%E3%80%91%E2%80%94%E2%80%94%E5%86%B3%E7%AD%96%E6%A0%91/" rel="next" title="机器学习面试题-决策树">
                  机器学习面试题-决策树 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






      

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      const activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      const commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

    </div>
  </main>

  <footer class="footer">
    <div class="footer-inner">
      

      

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Kayden</span>
</div>

    </div>
  </footer>

  
  <script src="//cdn.jsdelivr.net/npm/animejs@3.2.0/lib/anime.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/next-boot.js"></script>

  




  <script src="/js/local-search.js"></script>















  








  

  
      <script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              const target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    const script = document.createElement('script');
    script.src = '//cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js';
    script.defer = true;
    document.head.appendChild(script);
  } else {
    MathJax.startup.document.state(0);
    MathJax.typesetClear();
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>

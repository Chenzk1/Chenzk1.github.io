<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.2.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/mylogo-32x32-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/mylogo-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/mylogo-16x16-next.png">
  <link rel="mask-icon" href="/images/mylogo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.0/css/all.min.css">

<script class="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"chenzk1.github.io","root":"/","scheme":"Gemini","version":"8.0.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":false,"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"motion":{"enable":false,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}};
  </script>

  <meta name="description" content="[TOC] 1. 简单介绍决策树算法 决策树将算法组织成一颗树的形式。其实这就是将平时所说的if-then语句构建成了树的形式。决策树主要包括三个部分：内部节点、叶节点、边。内部节点是划分的特征，边代表划分的条件，叶节点表示类别。 构建决策树 就是一个递归的选择内部节点，计算划分条件的边，最后到达叶子节点的过程。 决策树在本质上是一组嵌套的if-else判定规则，从数学上看是分段常数函数，对应">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习面试题-决策树">
<meta property="og:url" content="https://chenzk1.github.io/2021/12/10/%E3%80%90%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%9D%A2%E8%AF%95%E9%A2%98%E3%80%91%E2%80%94%E2%80%94%E5%86%B3%E7%AD%96%E6%A0%91/index.html">
<meta property="og:site_name" content="Kayden&#39;s Blog">
<meta property="og:description" content="[TOC] 1. 简单介绍决策树算法 决策树将算法组织成一颗树的形式。其实这就是将平时所说的if-then语句构建成了树的形式。决策树主要包括三个部分：内部节点、叶节点、边。内部节点是划分的特征，边代表划分的条件，叶节点表示类别。 构建决策树 就是一个递归的选择内部节点，计算划分条件的边，最后到达叶子节点的过程。 决策树在本质上是一组嵌套的if-else判定规则，从数学上看是分段常数函数，对应">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2021-12-09T16:00:00.000Z">
<meta property="article:modified_time" content="2022-04-23T12:26:01.778Z">
<meta property="article:author" content="Kayden">
<meta property="article:tag" content="ML">
<meta property="article:tag" content="DecisionTree">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://chenzk1.github.io/2021/12/10/%E3%80%90%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%9D%A2%E8%AF%95%E9%A2%98%E3%80%91%E2%80%94%E2%80%94%E5%86%B3%E7%AD%96%E6%A0%91/">


<script class="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>机器学习面试题-决策树 | Kayden's Blog</title>
  






  <noscript>
  <style>
  body { margin-top: 2rem; }

  .use-motion .menu-item,
  .use-motion .sidebar,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header {
    visibility: visible;
  }

  .use-motion .header,
  .use-motion .site-brand-container .toggle,
  .use-motion .footer { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle,
  .use-motion .custom-logo-image {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line {
    transform: scaleX(1);
  }

  .search-pop-overlay, .sidebar-nav { display: none; }
  .sidebar-panel { display: block; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">Kayden's Blog</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">Mamba forever.</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <section class="post-toc-wrap sidebar-panel">
          <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-%E7%AE%80%E5%8D%95%E4%BB%8B%E7%BB%8D%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95"><span class="nav-number">1.</span> <span class="nav-text">1. 简单介绍决策树算法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-%E5%86%B3%E7%AD%96%E6%A0%91%E5%92%8C%E6%9D%A1%E4%BB%B6%E6%A6%82%E7%8E%87%E5%88%86%E5%B8%83%E7%9A%84%E5%85%B3%E7%B3%BB%EF%BC%9F"><span class="nav-number">2.</span> <span class="nav-text">2. 决策树和条件概率分布的关系？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-%E4%BF%A1%E6%81%AF%E5%A2%9E%E7%9B%8A%E6%AF%94%E7%9B%B8%E5%AF%B9%E4%BF%A1%E6%81%AF%E5%A2%9E%E7%9B%8A%E6%9C%89%E4%BB%80%E4%B9%88%E5%A5%BD%E5%A4%84%EF%BC%9F"><span class="nav-number">3.</span> <span class="nav-text">3. 信息增益比相对信息增益有什么好处？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-ID3%E7%AE%97%E6%B3%95%E2%80%94-gt-C4-5%E7%AE%97%E6%B3%95%E2%80%94-gt-CART%E7%AE%97%E6%B3%95"><span class="nav-number">4.</span> <span class="nav-text">4. ID3算法—&gt;C4.5算法—&gt; CART算法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-%E5%86%B3%E7%AD%96%E6%A0%91%E7%9A%84%E7%BC%BA%E5%A4%B1%E5%80%BC%E6%98%AF%E6%80%8E%E4%B9%88%E5%A4%84%E7%90%86%E7%9A%84"><span class="nav-number">5.</span> <span class="nav-text">5. 决策树的缺失值是怎么处理的</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-%E5%86%B3%E7%AD%96%E6%A0%91%E7%9A%84%E7%9B%AE%E6%A0%87%E5%87%BD%E6%95%B0%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="nav-number">6.</span> <span class="nav-text">6. 决策树的目标函数是什么？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#7-%E5%86%B3%E7%AD%96%E6%A0%91%E6%80%8E%E4%B9%88%E5%A4%84%E7%90%86%E8%BF%9E%E7%BB%AD%E6%80%A7%E7%89%B9%E5%BE%81%EF%BC%9F"><span class="nav-number">7.</span> <span class="nav-text">7. 决策树怎么处理连续性特征？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#8-%E5%86%B3%E7%AD%96%E6%A0%91%E6%80%8E%E4%B9%88%E9%98%B2%E6%AD%A2%E8%BF%87%E6%8B%9F%E5%90%88%EF%BC%9F"><span class="nav-number">8.</span> <span class="nav-text">8. 决策树怎么防止过拟合？</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9E%84%E5%BB%BA%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97"><span class="nav-number">8.1.</span> <span class="nav-text">构建随机森林</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%8E%A7%E5%88%B6%E6%A0%91%E7%9A%84%E7%BB%93%E6%9E%84%E5%A4%8D%E6%9D%82%E7%A8%8B%E5%BA%A6"><span class="nav-number">8.2.</span> <span class="nav-text">控制树的结构复杂程度</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#9-%E5%A6%82%E6%9E%9C%E7%89%B9%E5%BE%81%E5%BE%88%E5%A4%9A%EF%BC%8C%E5%86%B3%E7%AD%96%E6%A0%91%E4%B8%AD%E6%9C%80%E5%90%8E%E6%B2%A1%E6%9C%89%E7%94%A8%E5%88%B0%E7%9A%84%E7%89%B9%E5%BE%81%E4%B8%80%E5%AE%9A%E6%98%AF%E6%97%A0%E7%94%A8%E5%90%97%EF%BC%9F"><span class="nav-number">9.</span> <span class="nav-text">9. 如果特征很多，决策树中最后没有用到的特征一定是无用吗？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#10-%E5%86%B3%E7%AD%96%E6%A0%91%E7%9A%84%E4%BC%98%E7%BC%BA%E7%82%B9%EF%BC%9F"><span class="nav-number">10.</span> <span class="nav-text">10.决策树的优缺点？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#11-%E6%A0%91%E5%BD%A2%E7%BB%93%E6%9E%84%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%8D%E9%9C%80%E8%A6%81%E5%BD%92%E4%B8%80%E5%8C%96"><span class="nav-number">11.</span> <span class="nav-text">11. 树形结构为什么不需要归一化?</span></a></li></ol></div>
      </section>
      <!--/noindex-->

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Kayden</p>
  <div class="site-description" itemprop="description">Kayden's Blog</div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">60</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">16</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">71</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <a href="https://github.com/Chenzk1" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;Chenzk1" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:chenzk666@gmail.com" title="E-Mail → mailto:chenzk666@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>


  <div class="links-of-blogroll site-overview-item animated">
    <div class="links-of-blogroll-title"><i class="fa fa-globe fa-fw"></i>
      Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://andrewsher.github.io/" title="https:&#x2F;&#x2F;andrewsher.github.io&#x2F;" rel="noopener" target="_blank">Andrewsher's blog</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="http://shorey.tech/" title="http:&#x2F;&#x2F;shorey.tech&#x2F;" rel="noopener" target="_blank">Shorey's blog</a>
        </li>
    </ul>
  </div>

      </section>
        <div class="back-to-top animated">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">
      

      

  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="https://chenzk1.github.io/2021/12/10/%E3%80%90%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%9D%A2%E8%AF%95%E9%A2%98%E3%80%91%E2%80%94%E2%80%94%E5%86%B3%E7%AD%96%E6%A0%91/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Kayden">
      <meta itemprop="description" content="Kayden's Blog">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Kayden's Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          机器学习面试题-决策树
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2021-12-10 00:00:00" itemprop="dateCreated datePublished" datetime="2021-12-10T00:00:00+08:00">2021-12-10</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Edited on</span>
        <time title="Modified: 2022-04-23 20:26:01" itemprop="dateModified" datetime="2022-04-23T20:26:01+08:00">2022-04-23</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/MachineLearning/" itemprop="url" rel="index"><span itemprop="name">MachineLearning</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <meta name="referrer" content="no-referrer"/>

<p>[TOC]</p>
<h2 id="1-简单介绍决策树算法"><a href="#1-简单介绍决策树算法" class="headerlink" title="1. 简单介绍决策树算法"></a>1. 简单介绍决策树算法</h2><ul>
<li>决策树将算法组织成一颗树的形式。其实这就是将平时所说的<strong>if-then语句</strong>构建成了树的形式。决策树主要包括<strong>三个部分：内部节点、叶节点、边。内部节点是划分的特征，边代表划分的条件，叶节点表示类别。</strong></li>
<li>构建决策树 就是一个递归的选择内部节点，计算划分条件的边，最后到达叶子节点的过程。 决策树在本质上是一组嵌套的if-else判定规则，从数学上看是分段常数函数，对应于用平行于坐标轴的平面对空间的划分。判定规则是人类处理很多问题时的常用方法，这些规则是我们通过经验总结出来的，而决策树的这些规则是通过训练样本自动学习得到的。</li>
<li>训练时，通过最大化Gini或者其他指标来寻找最佳分裂。决策树可以输特征向量每个分量的重要性。</li>
<li><strong>决策树是一种判别模型，既支持分类问题，也支持回归问题，是一种非线性模型（分段线性函数不是线性的）。它天然的支持多分类问题。</strong></li>
</ul>
<a id="more"></a>
<h2 id="2-决策树和条件概率分布的关系？"><a href="#2-决策树和条件概率分布的关系？" class="headerlink" title="2. 决策树和条件概率分布的关系？"></a>2. 决策树和条件概率分布的关系？</h2><p><strong>决策树可以表示成给定条件下类的条件概率分布。</strong> </p>
<p>决策树中的每一条路径都对应是划分的一个条件概率分布. 每一个叶子节点都是通过多个条件之后的划分空间，在叶子节点中计算每个类的条件概率，必然会倾向于某一个类，即这个类的概率最大。</p>
<h2 id="3-信息增益比相对信息增益有什么好处？"><a href="#3-信息增益比相对信息增益有什么好处？" class="headerlink" title="3. 信息增益比相对信息增益有什么好处？"></a>3. 信息增益比相对信息增益有什么好处？</h2><ul>
<li><p>使用信息增益时：模型<strong>偏向于选择取值较多</strong>的特征</p>
</li>
<li><p>使用信息增益比时：<strong>对取值多的特征加上的惩罚</strong>，对这个问题进行了校正。</p>
</li>
</ul>
<h2 id="4-ID3算法—-gt-C4-5算法—-gt-CART算法"><a href="#4-ID3算法—-gt-C4-5算法—-gt-CART算法" class="headerlink" title="4. ID3算法—&gt;C4.5算法—&gt; CART算法"></a>4. ID3算法—&gt;C4.5算法—&gt; CART算法</h2><ul>
<li><p>$ID3$</p>
<ul>
<li>$ID3$算法没有考虑连续特征，比如长度，密度都是连续值，无法在ID3运用。这大大限制了ID3的用途。</li>
<li>$ID3$算法采用信息增益大的特征优先建立决策树的节点，偏向于取值比较多的特征</li>
<li>$ID3$算法对于缺失值的情况没有做考虑</li>
<li>$ID3$算法没有考虑过拟合的问题</li>
</ul>
</li>
<li><p>$C4.5$在$ID3$算法上面的改进</p>
<ul>
<li>连续的特征离散化 </li>
<li>使用信息增益比 </li>
<li>通过剪枝算法解决过拟合</li>
</ul>
</li>
<li><p>$C4.5$的不足：</p>
<ul>
<li>$C4.5$生成的是多叉树</li>
<li>$C4.5$只能用于分类，如果能将决策树用于回归的话可以扩大它的使用范围。</li>
<li>$C4.5$由于使用了熵模型，里面有大量的耗时的对数运算,如果是连续值还有大量的排序运算</li>
</ul>
</li>
<li><p>$CART$算法 </p>
<ul>
<li>可以做回归，也可以做分类， </li>
<li>使用基尼系数来代替信息增益比 </li>
<li>$CART$分类树离散值的处理问题，采用的思路是不停的二分离散特征。 </li>
</ul>
</li>
</ul>
<h2 id="5-决策树的缺失值是怎么处理的"><a href="#5-决策树的缺失值是怎么处理的" class="headerlink" title="5. 决策树的缺失值是怎么处理的"></a>5. 决策树的缺失值是怎么处理的</h2><ul>
<li><p>如何在特征值缺失的情况下进行划分特征的选择？</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">（比如“色泽”这个特征有的样本在该特征上的值是缺失的，那么该如何计算“色泽”的信息增益？）</span><br></pre></td></tr></table></figure>
<ul>
<li><p>每个样本设置一个权重（初始可以都为1） </p>
</li>
<li><p>划分数据，一部分是有特征值$a$的数据，另一部分是没有特征值$a$的数据,记为$\tilde{D}$，</p>
</li>
<li><p><strong>对</strong>没有缺失特征值$a$的<strong>数据集$\tilde{D}$，</strong>来和对应的特征$A$的各个特征值一起<strong>计算加权重后的信息增益比</strong>，最后乘上一个系数$\rho$ 。</p>
</li>
</ul>
</li>
</ul>
<script type="math/tex; mode=display">
\rho=\frac{\sum_{x \in \tilde{D}} w_{x}}{\sum_{x \in {D}} w_{x}}</script><script type="math/tex; mode=display">
\tilde{p}_{k}=\frac{\sum_{x \in \tilde{D}_{k}} w_{x}}{\sum_{x \in \tilde{D}} w_{x}} \quad(1 \leq \mathrm{k} \leq|y|)</script><script type="math/tex; mode=display">
\tilde{r}_{v}=\frac{\sum_{x \in \tilde D^{v}} w_{x}}{\sum_{x \in \tilde{D}} w_{x}} \quad(1 \leq v \leq V)</script><p>​        假设特征$A$有$v$个取值${a_1,a_2 \dots a_v}$</p>
<p>​        $\tilde D$：该特征上没有缺失值的样本</p>
<p>​        $\tilde D_k$：$\tilde D$中属于第$k$类的样本子集</p>
<p>​        $\tilde D^v$：$\tilde D$中在特征$a$上取值为$a_v$的样本子集</p>
<p>​        $\rho$：无特征$A$缺失的样本加权后所占加权总样本的比例。</p>
<p>​        $\tilde{p}_{k}$：无缺失值样本第$k$类所占无缺失值样本的比例</p>
<p>​        $\tilde{r}_{v}$：无缺失值样本在特征$a$上取值$a^v$的样本所占无缺失值样本的比例</p>
<p>​        新的信息增益公式：</p>
<script type="math/tex; mode=display">
\begin{aligned}
&\operatorname{Gain}(D, a)=\rho \times \operatorname{Gain}(\tilde{D}, a)=\rho \times\left(\operatorname{Ent}(\tilde{D})-\sum_{v=1}^{V} \tilde{r}_{v} \operatorname{Ent}\left(\tilde{D}^{v}\right)\right)\\
&\operatorname{Ent}(\tilde{D})=-\sum_{k=1}^{|y|} \tilde{p}_{k} \log _{2} \tilde{p}_{k}
\end{aligned}</script><ul>
<li><p>给定划分特征，若样本在该特征上的值是缺失的，那么该如何对这个样本进行划分？</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">（即到底把这个样本划分到哪个结点里？）</span><br></pre></td></tr></table></figure>
<ul>
<li>让包含缺失值的样本以不同的概率划分到不同的子节点中去。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">比如缺失特征A的样本a之前权重为1，特征A有3个特征值A1,A2,A3。 3个特征值对应的无缺失A特征的样本个数为2,3,4.则a同时划分入A1，A2，A3。对应权重调节为2&#x2F;9,3&#x2F;9, 4&#x2F;9。</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="6-决策树的目标函数是什么？"><a href="#6-决策树的目标函数是什么？" class="headerlink" title="6. 决策树的目标函数是什么？"></a><strong>6. 决策树的目标函数是什么？</strong></h2><script type="math/tex; mode=display">
C_{\alpha}(T)=\sum_{t=1}^{|T|} N_{t} H_{t}(T)+a|T|</script><script type="math/tex; mode=display">
H_{t}(T)=-\sum_{k} \frac{N_{t k}}{N_{t}} \log \frac{N_{t k}}{N_{t}}</script><p>其中$|T|$代表叶节点个数</p>
<p>$N_t$表示具体某个叶节点的样例数</p>
<p> $H_t(T)$ 表示叶节点$t$上的经验熵</p>
<p>$\alpha|T|$为正则项，$\alpha \geqslant 0 $ 为参数。</p>
<h2 id="7-决策树怎么处理连续性特征？"><a href="#7-决策树怎么处理连续性特征？" class="headerlink" title="7. 决策树怎么处理连续性特征？"></a>7. 决策树怎么处理连续性特征？</h2><p>因为连续特征的可取值数目不再有限，因此不能像前面处理离散特征枚举离散特征取值来对结点进行划分。因此需要连续特征离散化，常用的离散化策略是二分法，这个技术也是$C4.5$中采用的策略。下面来具体介绍下，如何采用二分法对连续特征离散化： </p>
<ul>
<li><p>训练集D，连续特征$A$，其中A有n个取值</p>
</li>
<li><p>对$A$的取值进行从小到大排序得到：${a_1,a_2\dots a_n}$</p>
</li>
<li><p>寻找划分点$t$，$t$将D分为子集$D<em>{t}^{-}$与$D</em>{t}^{+}$</p>
<ul>
<li>$D_{t}^{-}$：特征$A$上取值不大于$t$的样本</li>
<li>$D_{t}^{+}$：特征$A$上取值大于$t$的样本</li>
</ul>
</li>
<li><p>对相邻的特征取值$a<em>i$与$a</em>{i+1}$，t再区间$[a<em>i,a</em>{i+1})$中取值所产生的划分结果相同，因此对于连续特征$A$,包含有$n-1$个元素的后选划分点集合</p>
</li>
</ul>
<script type="math/tex; mode=display">
T_a = \{\frac{a_i + a_{i+1}}{2}|1\leq{i}\leq{n-1} \}</script><ul>
<li><p>把区间$[a<em>i,a</em>{i+1})$的中位点$\frac{a<em>i + a</em>{i+1}}{2}$作为候选划分点</p>
</li>
<li><p>按照处理离散值那样来选择最优的划分点,使用公式：</p>
<script type="math/tex; mode=display">
Gain(D,a) =\underbrace{max}_{t\in T_a}Gain(D,a,t) = \underbrace{max}_{t\in T_a}\ (Ent(D) - \sum_{\lambda \in \{-,+ \}}\frac{|D_t^{\lambda}|}{|D|}Ent(D_t^{\lambda}))</script><p>其中$Gain(D,a,t)$是样本集$D$基于划分点$t$二分之后的信息增益。划分点时候选择使用$Gain(D,a,t)$最大的划分点。</p>
</li>
</ul>
<h2 id="8-决策树怎么防止过拟合？"><a href="#8-决策树怎么防止过拟合？" class="headerlink" title="8. 决策树怎么防止过拟合？"></a><strong>8. 决策树怎么防止过拟合？</strong></h2><h3 id="构建随机森林"><a href="#构建随机森林" class="headerlink" title="构建随机森林"></a>构建随机森林</h3><ul>
<li>构建随机森林</li>
</ul>
<h3 id="控制树的结构复杂程度"><a href="#控制树的结构复杂程度" class="headerlink" title="控制树的结构复杂程度"></a>控制树的结构复杂程度</h3><ul>
<li><p>预剪枝(提前停止)：控制<strong>深度、当前的节点数、分裂对测试集的准确度提升大小</strong></p>
<ul>
<li>限制树的高度，可以利用交叉验证选择</li>
<li>利用分类指标，如果下一次切分没有降低误差，则停止切分</li>
<li>限制树的节点个数，比如某个节点小于100个样本，停止对该节点切分</li>
</ul>
</li>
<li><p>后剪枝(自底而上)：<strong>生成决策树、交叉验证剪枝：子树删除，节点代替子树、测试集准确率判断决定剪枝</strong></p>
<ul>
<li>在决策树构建完成之后，根据加上正则项的结构风险最小化自下向上进行的剪枝操作. 剪枝的目的就是防止过拟合，是模型在测试数据上变现良好，更加鲁棒。</li>
</ul>
</li>
</ul>
<h2 id="9-如果特征很多，决策树中最后没有用到的特征一定是无用吗？"><a href="#9-如果特征很多，决策树中最后没有用到的特征一定是无用吗？" class="headerlink" title="9. 如果特征很多，决策树中最后没有用到的特征一定是无用吗？"></a>9. 如果特征很多，决策树中最后没有用到的特征一定是无用吗？</h2><p>不是无用的，从两个角度考虑：</p>
<ul>
<li><p><strong>特征替代性</strong>，如果可以已经使用的特征$A$和特征$B$可以提点特征$C$，特征$C$可能就没有被使用，但是如果把特征$C$单独拿出来进行训练，依然有效</p>
</li>
<li><p>决策树的每一条路径就是<strong>计算条件概率的条件</strong>，前面的条件如果包含了后面的条件，只是这个条件在这棵树中是无用的，如果把这个条件拿出来也是可以帮助分析数据.</p>
</li>
</ul>
<h2 id="10-决策树的优缺点？"><a href="#10-决策树的优缺点？" class="headerlink" title="10.决策树的优缺点？"></a>10.决策树的优缺点？</h2><ul>
<li><p>优点: </p>
<ul>
<li>简单直观，生成的决策树很直观。</li>
<li>基本不需要预处理，不需要提前归一化，处理缺失值。</li>
<li>既可以处理离散值也可以处理连续值。很多算法只是专注于离散值或者连续值。</li>
<li>可以处理多维度输出的分类问题。</li>
<li>相比于神经网络之类的黑盒分类模型，决策树在逻辑上可以得到很好的解释</li>
<li>可以交叉验证的剪枝来选择模型，从而提高泛化能力。</li>
<li>对于异常点的容错能力好，健壮性高。</li>
</ul>
</li>
<li><p>缺点:</p>
<ul>
<li>决策树算法非常容易过拟合，导致泛化能力不强。可以通过设置节点最少样本数量和限制决策树深度来改进。</li>
<li>决策树会因为样本发生一点点的改动，就会导致树结构的剧烈改变。这个可以通过集成学习之类的方法解决。</li>
<li>寻找最优的决策树是一个NP难的问题，我们一般是通过启发式方法，容易陷入局部最优。可以通过集成学习之类的方法来改善。</li>
<li>有些比较复杂的关系，决策树很难学习，比如异或。这个就没有办法了，一般这种关系可以换神经网络分类方法来解决。</li>
<li>如果某些特征的样本比例过大，生成决策树容易偏向于这些特征。这个可以通过调节样本权重来改善。</li>
</ul>
</li>
</ul>
<h2 id="11-树形结构为什么不需要归一化"><a href="#11-树形结构为什么不需要归一化" class="headerlink" title="11. 树形结构为什么不需要归一化?"></a>11. 树形结构为什么不需要归一化?</h2><ul>
<li><strong>数值缩放不影响分裂点位置，对树模型的结构不造成影响</strong>。</li>
<li><p>按照特征值进行排序的，排序的顺序不变，那么所属的分支以及分裂点就不会有不同。</p>
</li>
<li><p>树模型是<strong>不能进行梯度下降</strong>的，因为构建树模型（回归树）寻找最优点时是通过寻找最优分裂点完成的，因此<strong>树模型是阶跃的，阶跃点是不可导</strong>的，并且求导没意义，也就不需要归一化。</p>
</li>
</ul>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/ML/" rel="tag"># ML</a>
              <a href="/tags/DecisionTree/" rel="tag"># DecisionTree</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2021/12/10/%E3%80%90%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%9D%A2%E8%AF%95%E9%A2%98%E3%80%91%E2%80%94%E2%80%94%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D/" rel="prev" title="机器学习面试题-梯度下降">
                  <i class="fa fa-chevron-left"></i> 机器学习面试题-梯度下降
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2021/12/10/%E3%80%90%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%9D%A2%E8%AF%95%E9%A2%98%E3%80%91%E2%80%94%E2%80%94RNN+LSTM/" rel="next" title="机器学习面试题-RNN&LSTM">
                  机器学习面试题-RNN&LSTM <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






      

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      const activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      const commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

    </div>
  </main>

  <footer class="footer">
    <div class="footer-inner">
      

      

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Kayden</span>
</div>

    </div>
  </footer>

  
  <script src="//cdn.jsdelivr.net/npm/animejs@3.2.0/lib/anime.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/next-boot.js"></script>

  




  <script src="/js/local-search.js"></script>















  








  

  
      <script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              const target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    const script = document.createElement('script');
    script.src = '//cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js';
    script.defer = true;
    document.head.appendChild(script);
  } else {
    MathJax.startup.document.state(0);
    MathJax.typesetClear();
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
